{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707f574d",
   "metadata": {},
   "source": [
    "## LAB-2 \n",
    "## DATE: 09.08.2023\n",
    "## Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4603a6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bitch.n.04'),\n",
       " Synset('dog.n.01'),\n",
       " Synset('fox.n.01'),\n",
       " Synset('hyena.n.01'),\n",
       " Synset('jackal.n.01'),\n",
       " Synset('wild_dog.n.01'),\n",
       " Synset('wolf.n.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "syn = wn.synsets('dog')[0]\n",
    "#syn.name()\n",
    "#syn.definition()\n",
    "#syn.examples()\n",
    "#syn.hypernyms()\n",
    "syn.hypernyms()[0].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "224307a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'domestic_dog'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "syn = wn.synsets('dog')[0]\n",
    "lemmas = syn.lemmas()\n",
    "len(lemmas)\n",
    "lemmas[1].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85207cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evil'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "syn1 = wn.synset('good.n.02')\n",
    "antonym1 = syn1.lemmas()[0].antonyms()[0]\n",
    "antonym1.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00bb4d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the->7  country->1  was->3  on->2  fire->1  communal->1  riots->1  had->2  paralyzed->1  most->1  of->5  state->1  reyaz->4  with->2  help->1  a->5  friend->1  got->1  fake->1  identity->2  cardhis->1  new->1  name->1  rakeshand->1  booked->1  ticket->2  to->3  aligarh->2  checker->1  train->1  asked->2  for->2  his->2  identificationreyaz->1  nervously->1  showed->1  one->1  he->2  recently->1  procured->1  seemed->1  satisfied->1  and->2  heaved->1  sigh->1  reliefat->1  there->1  none->1  fear->1  assalamu->1  alaikum->1  said->1  ward->1  off->1  group->1  enraged->1  people->1  angriest->1  them->1  bloodshot->1  eyes->1  approached->1  card->1  \n",
      "\n",
      "The number of unique words : 63\n",
      "The total is : 95\n",
      "\n",
      "thecountry->1  countrywas->1  wason->1  onfire->1  firecommunal->1  communalriots->1  riotshad->1  hadparalyzed->1  paralyzedmost->1  mostof->1  ofthe->1  thestate->1  statereyaz->1  reyazwith->1  withthe->1  thehelp->1  helpof->1  ofa->1  afriend->1  friendgot->1  gota->1  afake->1  fakeidentity->1  identitycardhis->1  cardhisnew->1  newname->1  namewas->1  wasrakeshand->1  rakeshandbooked->1  bookeda->1  aticket->1  ticketto->1  toaligarh->1  aligarhthe->1  theticket->1  ticketchecker->1  checkeron->1  onthe->1  thetrain->1  trainasked->1  askedfor->2  forhis->2  hisidentificationreyaz->1  identificationreyaznervously->1  nervouslyshowed->1  showedthe->1  theone->1  onehe->1  hehad->1  hadrecently->1  recentlyprocured->1  procuredhe->1  heseemed->1  seemedsatisfied->1  satisfiedand->1  andreyaz->1  reyazheaved->1  heaveda->1  asigh->1  sighof->1  ofreliefat->1  reliefataligarh->1  aligarhthere->1  therewas->1  wasnone->1  noneto->1  tofear->1  fearassalamu->1  assalamualaikum->1  alaikumsaid->1  saidreyaz->1  reyazto->1  toward->1  wardoff->1  offa->1  agroup->1  groupof->1  ofenraged->1  enragedpeople->1  peoplethe->1  theangriest->1  angriestof->1  ofthem->1  themwith->1  withbloodshot->1  bloodshoteyes->1  eyesapproached->1  approachedreyaz->1  reyazand->1  andasked->1  hisidentity->1  identitycard->1  \n",
      "\n",
      "The max words pair is : 2\n",
      "The min words pair is : 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "s = \"The country was on fire. Communal riots had paralyzed most of the state. Reyaz, with the help of a friend, got a fake identity card--his new name was Rakesh--and booked a ticket to Aligarh. The ticket checker on the train asked for his identification--Reyaz nervously showed the one he had recently procured. He seemed satisfied and Reyaz heaved a sigh of relief.At Aligarh there was none to fear. \\\"Assalamu alaikum,\\\" said Reyaz to ward off a group of enraged people. The angriest of them, with bloodshot eyes, approached Reyaz and asked for his identity card.\"\n",
    "translating = str.maketrans('', '', string.punctuation)\n",
    "S= s.translate(translating)\n",
    "l = word_tokenize(S.lower())\n",
    "elements_count = {}\n",
    "for i in l:\n",
    "    if i in elements_count:\n",
    "        elements_count[i] += 1\n",
    "    else:\n",
    "        elements_count[i] = 1\n",
    "for key, value in elements_count.items():\n",
    "   print(f\"{key}->{value}\",end='  ')\n",
    "print(\"\\n\\nThe number of unique words :\",len(elements_count.keys()))\n",
    "sum = 0\n",
    "for i in elements_count.values():\n",
    "    sum+=i\n",
    "print(\"The total is :\", sum)\n",
    "print()\n",
    "Elements_count = {}\n",
    "for i in range(len(l)):\n",
    "    if(i != len(l)-1):\n",
    "        a = l[i]+l[i+1]\n",
    "        if a in Elements_count:\n",
    "            Elements_count[a] += 1\n",
    "        else:\n",
    "            Elements_count[a] = 1\n",
    "for key, value in Elements_count.items():\n",
    "   print(f\"{key}->{value}\",end='  ')\n",
    "print(\"\\n\\nThe max words pair is :\",max(Elements_count.values()))\n",
    "print(\"The min words pair is :\",min(Elements_count.values()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
